{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6067e5a2",
   "metadata": {},
   "source": [
    "# Emotional State Identification Using BVP Signals\n",
    "\n",
    "This notebook demonstrates how to identify emotional states using Blood Volume Pulse (BVP) signals through signal processing and machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971c59da",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Import libraries such as NumPy, pandas, matplotlib, and scikit-learn for data processing, visualization, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6311b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b7de4c",
   "metadata": {},
   "source": [
    "## Load and Preprocess BVP Signal Data\n",
    "\n",
    "Load the BVP signal data from a file, handle missing values, and normalize the signal for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb3148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BVP signal data\n",
    "# Note: Replace 'bvp_data.csv' with your actual data file path\n",
    "# Expected format: CSV with columns 'timestamp', 'bvp_signal', 'emotion_label'\n",
    "\n",
    "def load_bvp_data(filepath):\n",
    "    \"\"\"\n",
    "    Load BVP signal data from a CSV file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(filepath)\n",
    "        print(f\"Data loaded successfully! Shape: {data.shape}\")\n",
    "        print(f\"Columns: {data.columns.tolist()}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Creating sample data for demonstration...\")\n",
    "        return create_sample_data()\n",
    "\n",
    "def create_sample_data():\n",
    "    \"\"\"\n",
    "    Create sample BVP data for demonstration purposes\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Simulate BVP signals for different emotional states\n",
    "    # 0: Neutral, 1: Happy, 2: Stressed, 3: Sad\n",
    "    emotions = []\n",
    "    bvp_signals = []\n",
    "    \n",
    "    for emotion in range(4):\n",
    "        for _ in range(n_samples // 4):\n",
    "            # Base signal with different characteristics for each emotion\n",
    "            t = np.linspace(0, 10, 640)  # 64 Hz sampling rate, 10 seconds\n",
    "            base_freq = 1.2 + emotion * 0.2  # Heart rate variability\n",
    "            amplitude = 100 + emotion * 20\n",
    "            \n",
    "            bvp = amplitude * np.sin(2 * np.pi * base_freq * t)\n",
    "            bvp += np.random.normal(0, 10, len(t))  # Add noise\n",
    "            \n",
    "            bvp_signals.append(bvp)\n",
    "            emotions.append(emotion)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'bvp_signal': bvp_signals,\n",
    "        'emotion_label': emotions\n",
    "    })\n",
    "\n",
    "# Load or create sample data\n",
    "df = load_bvp_data('bvp_data.csv')\n",
    "\n",
    "# Handle missing values\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    print(f\"Missing values found: {df.isnull().sum()}\")\n",
    "    df = df.dropna()\n",
    "    print(f\"Data after removing missing values: {df.shape}\")\n",
    "\n",
    "print(\"\\nData preprocessing completed!\")\n",
    "print(f\"Emotion distribution:\\n{df['emotion_label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119b702",
   "metadata": {},
   "source": [
    "## Visualize BVP Signal\n",
    "\n",
    "Plot the BVP signal to observe patterns and identify any anomalies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c58afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize BVP signals for different emotional states\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "emotion_labels = {0: 'Neutral', 1: 'Happy', 2: 'Stressed', 3: 'Sad'}\n",
    "\n",
    "for idx, (emotion_id, emotion_name) in enumerate(emotion_labels.items()):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # Get sample signal for this emotion\n",
    "    sample_signal = df[df['emotion_label'] == emotion_id]['bvp_signal'].iloc[0]\n",
    "    \n",
    "    if isinstance(sample_signal, np.ndarray):\n",
    "        signal_data = sample_signal\n",
    "    else:\n",
    "        signal_data = np.array(eval(sample_signal)) if isinstance(sample_signal, str) else sample_signal\n",
    "    \n",
    "    time = np.arange(len(signal_data)) / 64  # Assuming 64 Hz sampling rate\n",
    "    \n",
    "    ax.plot(time, signal_data, linewidth=0.8)\n",
    "    ax.set_title(f'BVP Signal - {emotion_name}', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax.set_ylabel('BVP Amplitude', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"BVP signals visualized for all emotional states!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49ffda3",
   "metadata": {},
   "source": [
    "## Extract Features from BVP Signal\n",
    "\n",
    "Extract features such as mean, standard deviation, frequency domain features, and other statistical measures from the BVP signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d1cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction from BVP signals\n",
    "\n",
    "def extract_time_domain_features(bvp_signal):\n",
    "    \"\"\"\n",
    "    Extract time-domain features from BVP signal\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        'mean': np.mean(bvp_signal),\n",
    "        'std': np.std(bvp_signal),\n",
    "        'min': np.min(bvp_signal),\n",
    "        'max': np.max(bvp_signal),\n",
    "        'median': np.median(bvp_signal),\n",
    "        'range': np.max(bvp_signal) - np.min(bvp_signal),\n",
    "        'skewness': skew(bvp_signal),\n",
    "        'kurtosis': kurtosis(bvp_signal),\n",
    "        'rms': np.sqrt(np.mean(bvp_signal**2))\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def extract_frequency_domain_features(bvp_signal, fs=64):\n",
    "    \"\"\"\n",
    "    Extract frequency-domain features from BVP signal\n",
    "    \"\"\"\n",
    "    # Compute power spectral density\n",
    "    freqs, psd = signal.welch(bvp_signal, fs=fs, nperseg=min(256, len(bvp_signal)))\n",
    "    \n",
    "    # Define frequency bands\n",
    "    lf_band = (0.04, 0.15)  # Low frequency\n",
    "    hf_band = (0.15, 0.4)   # High frequency\n",
    "    \n",
    "    # Calculate power in each band\n",
    "    lf_power = np.trapz(psd[(freqs >= lf_band[0]) & (freqs < lf_band[1])])\n",
    "    hf_power = np.trapz(psd[(freqs >= hf_band[0]) & (freqs < hf_band[1])])\n",
    "    \n",
    "    features = {\n",
    "        'lf_power': lf_power,\n",
    "        'hf_power': hf_power,\n",
    "        'lf_hf_ratio': lf_power / hf_power if hf_power > 0 else 0,\n",
    "        'total_power': np.trapz(psd),\n",
    "        'peak_frequency': freqs[np.argmax(psd)]\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def extract_all_features(bvp_signal):\n",
    "    \"\"\"\n",
    "    Extract all features from BVP signal\n",
    "    \"\"\"\n",
    "    # Convert to numpy array if needed\n",
    "    if isinstance(bvp_signal, str):\n",
    "        bvp_signal = np.array(eval(bvp_signal))\n",
    "    elif not isinstance(bvp_signal, np.ndarray):\n",
    "        bvp_signal = np.array(bvp_signal)\n",
    "    \n",
    "    # Extract features\n",
    "    time_features = extract_time_domain_features(bvp_signal)\n",
    "    freq_features = extract_frequency_domain_features(bvp_signal)\n",
    "    \n",
    "    # Combine all features\n",
    "    all_features = {**time_features, **freq_features}\n",
    "    return all_features\n",
    "\n",
    "# Extract features for all samples\n",
    "print(\"Extracting features from BVP signals...\")\n",
    "features_list = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    features = extract_all_features(row['bvp_signal'])\n",
    "    features['emotion_label'] = row['emotion_label']\n",
    "    features_list.append(features)\n",
    "\n",
    "# Create feature dataframe\n",
    "features_df = pd.DataFrame(features_list)\n",
    "\n",
    "print(f\"Feature extraction completed!\")\n",
    "print(f\"Total features extracted: {len(features_df.columns) - 1}\")\n",
    "print(f\"\\nFeature columns: {[col for col in features_df.columns if col != 'emotion_label']}\")\n",
    "print(f\"\\nFeature statistics:\\n{features_df.describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318976b",
   "metadata": {},
   "source": [
    "## Train a Classifier to Identify Emotional States\n",
    "\n",
    "Use a machine learning model (e.g., SVM, Random Forest) to classify emotional states based on the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "\n",
    "# Separate features and labels\n",
    "X = features_df.drop('emotion_label', axis=1)\n",
    "y = features_df['emotion_label']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")\n",
    "print(f\"\\nTraining emotion distribution:\\n{y_train.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6012d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple classifiers\n",
    "\n",
    "# 1. Random Forest Classifier\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "print(\"Random Forest training completed!\")\n",
    "\n",
    "# 2. Support Vector Machine\n",
    "print(\"\\nTraining Support Vector Machine...\")\n",
    "svm_model = SVC(\n",
    "    kernel='rbf',\n",
    "    C=1.0,\n",
    "    gamma='scale',\n",
    "    random_state=42\n",
    ")\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "print(\"SVM training completed!\")\n",
    "\n",
    "# Feature importance from Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'][:10], feature_importance['importance'][:10])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 10 Most Important Features for Emotion Classification', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f315556",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "Evaluate the performance of the classifier using metrics such as accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf23530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both models\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate a classification model\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{model_name} Performance Metrics\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, \n",
    "                                target_names=['Neutral', 'Happy', 'Stressed', 'Sad']))\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_predictions = evaluate_model(rf_model, X_test_scaled, y_test, \"Random Forest\")\n",
    "\n",
    "# Evaluate SVM\n",
    "svm_predictions = evaluate_model(svm_model, X_test_scaled, y_test, \"Support Vector Machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89deecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrices\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "emotion_names = ['Neutral', 'Happy', 'Stressed', 'Sad']\n",
    "\n",
    "# Random Forest confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, rf_predictions)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=emotion_names, yticklabels=emotion_names, ax=axes[0])\n",
    "axes[0].set_title('Random Forest - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('True Label', fontsize=12)\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "# SVM confusion matrix\n",
    "cm_svm = confusion_matrix(y_test, svm_predictions)\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=emotion_names, yticklabels=emotion_names, ax=axes[1])\n",
    "axes[1].set_title('SVM - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1467e4e",
   "metadata": {},
   "source": [
    "## Test on New Data\n",
    "\n",
    "Test the trained model on new BVP signal data to predict emotional states and validate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict emotion from new BVP signal\n",
    "\n",
    "def predict_emotion(bvp_signal, model, scaler, model_name=\"Random Forest\"):\n",
    "    \"\"\"\n",
    "    Predict emotion from a new BVP signal\n",
    "    \"\"\"\n",
    "    # Extract features\n",
    "    features = extract_all_features(bvp_signal)\n",
    "    features_df = pd.DataFrame([features])\n",
    "    \n",
    "    # Remove emotion label if present\n",
    "    if 'emotion_label' in features_df.columns:\n",
    "        features_df = features_df.drop('emotion_label', axis=1)\n",
    "    \n",
    "    # Ensure feature order matches training data\n",
    "    features_df = features_df[X.columns]\n",
    "    \n",
    "    # Scale features\n",
    "    features_scaled = scaler.transform(features_df)\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(features_scaled)[0]\n",
    "    \n",
    "    # Get probability if available\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probabilities = model.predict_proba(features_scaled)[0]\n",
    "    else:\n",
    "        probabilities = None\n",
    "    \n",
    "    emotion_map = {0: 'Neutral', 1: 'Happy', 2: 'Stressed', 3: 'Sad'}\n",
    "    \n",
    "    return {\n",
    "        'predicted_emotion': emotion_map[prediction],\n",
    "        'emotion_id': prediction,\n",
    "        'probabilities': probabilities\n",
    "    }\n",
    "\n",
    "# Test on a few new samples\n",
    "print(\"Testing on new BVP signals...\\n\")\n",
    "\n",
    "for i in range(min(5, len(df))):\n",
    "    test_signal = df['bvp_signal'].iloc[i]\n",
    "    true_emotion = df['emotion_label'].iloc[i]\n",
    "    emotion_map = {0: 'Neutral', 1: 'Happy', 2: 'Stressed', 3: 'Sad'}\n",
    "    \n",
    "    # Predict using Random Forest\n",
    "    result_rf = predict_emotion(test_signal, rf_model, scaler, \"Random Forest\")\n",
    "    \n",
    "    # Predict using SVM\n",
    "    result_svm = predict_emotion(test_signal, svm_model, scaler, \"SVM\")\n",
    "    \n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  True Emotion: {emotion_map[true_emotion]}\")\n",
    "    print(f\"  Random Forest Prediction: {result_rf['predicted_emotion']}\")\n",
    "    if result_rf['probabilities'] is not None:\n",
    "        print(f\"  RF Probabilities: {dict(zip(emotion_map.values(), result_rf['probabilities']))}\")\n",
    "    print(f\"  SVM Prediction: {result_svm['predicted_emotion']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff466e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction results on test samples\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "emotion_map = {0: 'Neutral', 1: 'Happy', 2: 'Stressed', 3: 'Sad'}\n",
    "\n",
    "for i in range(4):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    \n",
    "    # Get test sample\n",
    "    test_idx = i * 10  # Sample every 10th test point\n",
    "    if test_idx < len(X_test):\n",
    "        test_signal = df.iloc[X_test.index[test_idx]]['bvp_signal']\n",
    "        true_emotion = y_test.iloc[test_idx]\n",
    "        \n",
    "        # Convert signal to array if needed\n",
    "        if isinstance(test_signal, str):\n",
    "            signal_data = np.array(eval(test_signal))\n",
    "        elif isinstance(test_signal, np.ndarray):\n",
    "            signal_data = test_signal\n",
    "        else:\n",
    "            signal_data = np.array(test_signal)\n",
    "        \n",
    "        # Predict emotion\n",
    "        result = predict_emotion(test_signal, rf_model, scaler)\n",
    "        \n",
    "        # Plot signal\n",
    "        time = np.arange(len(signal_data)) / 64\n",
    "        ax.plot(time, signal_data, linewidth=0.8)\n",
    "        \n",
    "        # Add title with prediction results\n",
    "        title = f\"True: {emotion_map[true_emotion]} | Predicted: {result['predicted_emotion']}\"\n",
    "        color = 'green' if emotion_map[true_emotion] == result['predicted_emotion'] else 'red'\n",
    "        ax.set_title(title, fontsize=12, fontweight='bold', color=color)\n",
    "        ax.set_xlabel('Time (seconds)', fontsize=10)\n",
    "        ax.set_ylabel('BVP Amplitude', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Prediction visualization completed!\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Emotion Identification from BVP Signals - Complete!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a8a20",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Data Loading**: Loaded and preprocessed BVP signal data\n",
    "2. **Visualization**: Visualized BVP signals for different emotional states\n",
    "3. **Feature Extraction**: Extracted time-domain and frequency-domain features\n",
    "4. **Model Training**: Trained Random Forest and SVM classifiers\n",
    "5. **Evaluation**: Achieved classification performance with multiple metrics\n",
    "6. **Prediction**: Successfully predicted emotions from new BVP signals\n",
    "\n",
    "### Next Steps:\n",
    "- Collect real BVP data from wearable devices (e.g., Empatica E4)\n",
    "- Experiment with deep learning models (LSTM, CNN)\n",
    "- Implement real-time emotion detection\n",
    "- Add more emotional states for finer-grained classification\n",
    "- Optimize feature selection using techniques like PCA or feature selection algorithms\n",
    "- Cross-validate results across multiple subjects"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
